{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "4ca86dbf3feea718",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T11:35:07.537283800Z",
     "start_time": "2024-04-09T11:35:07.534275700Z"
    }
   },
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torchvision.transforms as transforms\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "initial_id",
   "metadata": {
    "collapsed": true,
    "ExecuteTime": {
     "end_time": "2024-04-09T11:35:07.942255Z",
     "start_time": "2024-04-09T11:35:07.937249700Z"
    }
   },
   "outputs": [],
   "source": [
    "class AlexNetModel(nn.Module):\n",
    "    def __init__(self, num_classes=38):\n",
    "        super(AlexNetModel, self).__init__()\n",
    "        \n",
    "        # Define data augmentation and normalization layers\n",
    "        self.transform_train = transforms.Compose([\n",
    "            transforms.RandomHorizontalFlip(),\n",
    "            transforms.RandomCrop(227),\n",
    "            transforms.ToTensor(),  # Convert PIL image to tensor\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        self.transform_test = transforms.Compose([\n",
    "            transforms.Resize(256),\n",
    "            transforms.CenterCrop(227),\n",
    "            transforms.ToTensor(),\n",
    "            transforms.Normalize(mean=[0.485, 0.456, 0.406], std=[0.229, 0.224, 0.225])\n",
    "        ])\n",
    "        \n",
    "        # Define convolutional layers\n",
    "        self.conv1 = nn.Conv2d(3, 96, kernel_size=11, stride=4)\n",
    "        self.conv2 = nn.Conv2d(96, 256, kernel_size=5, padding=2, groups=2)\n",
    "        self.conv3 = nn.Conv2d(256, 384, kernel_size=3, padding=1)\n",
    "        self.conv4 = nn.Conv2d(384, 384, kernel_size=3, padding=1, groups=2)\n",
    "        self.conv5 = nn.Conv2d(384, 256, kernel_size=3, padding=1, groups=2)\n",
    "        \n",
    "        # Define normalization and pooling layers\n",
    "        self.norm1 = nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75)\n",
    "        self.norm2 = nn.LocalResponseNorm(size=5, alpha=0.0001, beta=0.75)\n",
    "        self.pool1 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.pool2 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        self.pool5 = nn.MaxPool2d(kernel_size=3, stride=2)\n",
    "        \n",
    "        # Define fully connected layers\n",
    "        self.fc6 = nn.Linear(256 * 6 * 6, 4096)\n",
    "        self.fc7 = nn.Linear(4096, 4096)\n",
    "        self.fc8 = nn.Linear(4096, num_classes)\n",
    "        \n",
    "        # Define dropout layer\n",
    "        self.dropout = nn.Dropout(p=0.5)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Data augmentation and normalization\n",
    "        if self.training:\n",
    "            x = self.transform_train(x)\n",
    "        else:\n",
    "            x = self.transform_test(x)\n",
    "        \n",
    "        # Convolutional layers with ReLU and normalization\n",
    "        x = F.relu(self.conv1(x))\n",
    "        x = self.norm1(x)\n",
    "        x = self.pool1(x)\n",
    "        \n",
    "        x = F.relu(self.conv2(x))\n",
    "        x = self.norm2(x)\n",
    "        x = self.pool2(x)\n",
    "        \n",
    "        x = F.relu(self.conv3(x))\n",
    "        x = F.relu(self.conv4(x))\n",
    "        x = F.relu(self.conv5(x))\n",
    "        x = self.pool5(x)\n",
    "        \n",
    "        # Flatten and pass through fully connected layers with dropout\n",
    "        x = x.view(-1, 256 * 6 * 6)\n",
    "        x = F.relu(self.fc6(x))\n",
    "        x = self.dropout(x)\n",
    "        x = F.relu(self.fc7(x))\n",
    "        x = self.dropout(x)\n",
    "        x = self.fc8(x)\n",
    "        \n",
    "        return x"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "9b79a80b9880a677",
   "metadata": {
    "collapsed": false,
    "ExecuteTime": {
     "end_time": "2024-04-09T11:35:08.433863200Z",
     "start_time": "2024-04-09T11:35:08.339842600Z"
    }
   },
   "outputs": [
    {
     "ename": "AttributeError",
     "evalue": "module 'torchvision.transforms' has no attribute 'Resize'",
     "output_type": "error",
     "traceback": [
      "\u001B[1;31m---------------------------------------------------------------------------\u001B[0m",
      "\u001B[1;31mAttributeError\u001B[0m                            Traceback (most recent call last)",
      "Cell \u001B[1;32mIn[10], line 1\u001B[0m\n\u001B[1;32m----> 1\u001B[0m model \u001B[38;5;241m=\u001B[39m \u001B[43mAlexNetModel\u001B[49m\u001B[43m(\u001B[49m\u001B[43m)\u001B[49m\n",
      "Cell \u001B[1;32mIn[9], line 13\u001B[0m, in \u001B[0;36mAlexNetModel.__init__\u001B[1;34m(self, num_classes)\u001B[0m\n\u001B[0;32m      5\u001B[0m \u001B[38;5;66;03m# Define data augmentation and normalization layers\u001B[39;00m\n\u001B[0;32m      6\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform_train \u001B[38;5;241m=\u001B[39m transforms\u001B[38;5;241m.\u001B[39mCompose([\n\u001B[0;32m      7\u001B[0m     transforms\u001B[38;5;241m.\u001B[39mRandomHorizontalFlip(),\n\u001B[0;32m      8\u001B[0m     transforms\u001B[38;5;241m.\u001B[39mRandomCrop(\u001B[38;5;241m227\u001B[39m),\n\u001B[0;32m      9\u001B[0m     transforms\u001B[38;5;241m.\u001B[39mToTensor(),  \u001B[38;5;66;03m# Convert PIL image to tensor\u001B[39;00m\n\u001B[0;32m     10\u001B[0m     transforms\u001B[38;5;241m.\u001B[39mNormalize(mean\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m0.485\u001B[39m, \u001B[38;5;241m0.456\u001B[39m, \u001B[38;5;241m0.406\u001B[39m], std\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m0.229\u001B[39m, \u001B[38;5;241m0.224\u001B[39m, \u001B[38;5;241m0.225\u001B[39m])\n\u001B[0;32m     11\u001B[0m ])\n\u001B[0;32m     12\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mtransform_test \u001B[38;5;241m=\u001B[39m transforms\u001B[38;5;241m.\u001B[39mCompose([\n\u001B[1;32m---> 13\u001B[0m     \u001B[43mtransforms\u001B[49m\u001B[38;5;241;43m.\u001B[39;49m\u001B[43mResize\u001B[49m(\u001B[38;5;241m256\u001B[39m),\n\u001B[0;32m     14\u001B[0m     transforms\u001B[38;5;241m.\u001B[39mCenterCrop(\u001B[38;5;241m227\u001B[39m),\n\u001B[0;32m     15\u001B[0m     transforms\u001B[38;5;241m.\u001B[39mToTensor(),\n\u001B[0;32m     16\u001B[0m     transforms\u001B[38;5;241m.\u001B[39mNormalize(mean\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m0.485\u001B[39m, \u001B[38;5;241m0.456\u001B[39m, \u001B[38;5;241m0.406\u001B[39m], std\u001B[38;5;241m=\u001B[39m[\u001B[38;5;241m0.229\u001B[39m, \u001B[38;5;241m0.224\u001B[39m, \u001B[38;5;241m0.225\u001B[39m])\n\u001B[0;32m     17\u001B[0m ])\n\u001B[0;32m     19\u001B[0m \u001B[38;5;66;03m# Define convolutional layers\u001B[39;00m\n\u001B[0;32m     20\u001B[0m \u001B[38;5;28mself\u001B[39m\u001B[38;5;241m.\u001B[39mconv1 \u001B[38;5;241m=\u001B[39m nn\u001B[38;5;241m.\u001B[39mConv2d(\u001B[38;5;241m3\u001B[39m, \u001B[38;5;241m96\u001B[39m, kernel_size\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m11\u001B[39m, stride\u001B[38;5;241m=\u001B[39m\u001B[38;5;241m4\u001B[39m)\n",
      "\u001B[1;31mAttributeError\u001B[0m: module 'torchvision.transforms' has no attribute 'Resize'"
     ]
    }
   ],
   "source": [
    "model = AlexNetModel()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e02046eb4f8a219",
   "metadata": {
    "collapsed": false
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.0"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
